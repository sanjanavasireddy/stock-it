# Stock-IT â€” Real-Time Financial Trade Monitoring System

![Python](https://img.shields.io/badge/Python-3.11-blue?logo=python)
![Kafka](https://img.shields.io/badge/Apache_Kafka-2.3-black?logo=apachekafka)
![Redis](https://img.shields.io/badge/Redis-7.2-red?logo=redis)
![FastAPI](https://img.shields.io/badge/FastAPI-0.104-green?logo=fastapi)
![Docker](https://img.shields.io/badge/Docker-Compose-blue?logo=docker)
![TimescaleDB](https://img.shields.io/badge/TimescaleDB-PostgreSQL-orange)
![Grafana](https://img.shields.io/badge/Grafana-10.1-orange?logo=grafana)
![Prometheus](https://img.shields.io/badge/Prometheus-2.47-red?logo=prometheus)

An end-to-end **streaming data pipeline** that ingests, processes, detects anomalies, and visualizes financial trade data in real time â€” built with a Lambda architecture using Apache Kafka, Redis, and TimescaleDB.

---

## Live Demo

> Dashboard: [https://tinyurl.com/trade-monitor-stock-it](https://tinyurl.com/trade-monitor-stock-it)
>
> *(Requires local Docker setup â€” see Quick Start below)*

---

## Dashboard Features

| Tab | What it shows |
|---|---|
| **Dashboard** | Live price watchlist (Stocks / Crypto / Forex), 1-min candlestick chart, order book depth, scrolling trade tape, alert feed, top movers |
| **Scanner** | Sortable table â€” Symbol, Price, Change %, VWAP, Volume, Buy/Sell pressure bar, BUY/SELL/NEUTRAL signal |
| **Alerts** | Full alert history with severity filter (Critical / High / Medium) |
| **ðŸ‹ Whales** | Volume spike alerts shown as whale cards with multiplier badge (e.g. 5.4x normal) |

**Dashboard highlights:**
- Scrolling live ticker tape at top
- Per-symbol sparkline mini-charts with flash-on-tick animation
- Candlestick chart (Canvas API) with OHLCV stats and VWAP line
- Order book bid/ask depth with fill bars
- Symbol detail modal (click any price card) â€” candlestick, OHLCV, buy/sell pressure, order book
- Sound alerts (Web Audio API) â€” 880Hz CRITICAL, 660Hz HIGH, 440Hz MEDIUM
- Toast pop-ups for CRITICAL/HIGH alerts
- CSV export of last 500 trades
- WebSocket latency meter

---

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    STOCK-IT PIPELINE                              â”‚
â”‚                                                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   raw-trades    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚  â”‚   Producer   â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º â”‚ Stream Processor â”‚           â”‚
â”‚  â”‚              â”‚                 â”‚                  â”‚           â”‚
â”‚  â”‚ GBM price    â”‚                 â”‚ â€¢ VWAP (incr.)   â”‚           â”‚
â”‚  â”‚ simulation   â”‚                 â”‚ â€¢ OHLCV windows  â”‚           â”‚
â”‚  â”‚ 10 symbols   â”‚                 â”‚   (1m/5m/15m)    â”‚           â”‚
â”‚  â”‚ ~50 msg/sec  â”‚                 â”‚ â€¢ Anomaly detect â”‚           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚                                            â”‚                     â”‚
â”‚                              trade-alerts  â”‚  trade-aggregates   â”‚
â”‚                                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚                                  â”‚                    â”‚          â”‚
â”‚                                  â–¼                    â–¼          â”‚
â”‚                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚                       â”‚  Alert Engine    â”‚   â”‚  FastAPI     â”‚   â”‚
â”‚                       â”‚                  â”‚   â”‚              â”‚   â”‚
â”‚                       â”‚ â€¢ Dedup (Redis)  â”‚   â”‚ REST / WS    â”‚   â”‚
â”‚                       â”‚ â€¢ Circuit breakerâ”‚   â”‚ SSE          â”‚   â”‚
â”‚                       â”‚ â€¢ Webhook routingâ”‚   â”‚              â”‚   â”‚
â”‚                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                      â”‚           â”‚
â”‚                                              â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚                                              â”‚  Dashboard   â”‚   â”‚
â”‚                                              â”‚  (HTML/JS)   â”‚   â”‚
â”‚                                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                   â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚   â”‚                     Data Layer                          â”‚     â”‚
â”‚   â”‚   Redis (speed layer)        TimescaleDB (batch layer) â”‚     â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                                                                   â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚   â”‚                  Monitoring Stack                        â”‚     â”‚
â”‚   â”‚      Prometheus (metrics scraping)   Grafana (viz)     â”‚     â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Tech Stack

| Layer | Technology | Purpose |
|---|---|---|
| **Ingestion** | Apache Kafka | 3 topics, partitioned by symbol, durable log |
| **Processing** | Python (confluent-kafka) | VWAP, OHLCV windows, anomaly detection |
| **Speed Layer** | Redis | Latest prices, rolling buffers, alert dedup |
| **Batch Layer** | TimescaleDB | Hypertables, continuous aggregates, 30-day retention |
| **API** | FastAPI | REST + WebSocket + SSE endpoints |
| **Dashboard** | Vanilla HTML/JS | Canvas candlesticks, WebSocket streaming |
| **Monitoring** | Prometheus + Grafana | Pipeline metrics, alerting |
| **Orchestration** | Docker Compose | 11 services, health checks, restart policies |

---

## Services & Ports

| Service | Port | Description |
|---|---|---|
| **Dashboard / API** | `8088` | FastAPI + live trading dashboard |
| **Kafka UI** | `8090` | Inspect topics, messages, consumer groups |
| **Grafana** | `3001` | Pre-built pipeline monitoring dashboard |
| **Prometheus** | `9090` | Metrics scraping |
| **TimescaleDB** | `5433` | Time-series PostgreSQL |
| **Redis** | `6379` | State store |
| **Producer metrics** | `8001` | Prometheus scrape endpoint |
| **Processor metrics** | `8002` | Prometheus scrape endpoint |
| **Alert Engine metrics** | `8003` | Prometheus scrape endpoint |

---

## Kafka Topics

| Topic | Producer | Consumer | Purpose |
|---|---|---|---|
| `raw-trades` | Trade Producer | Stream Processor | Raw trade events, partitioned by symbol |
| `trade-alerts` | Stream Processor | Alert Engine + API | Anomaly alert events |
| `trade-aggregates` | Stream Processor | API | Completed OHLCV window events |

---

## Anomaly Detection

| Alert Type | Severity | Trigger Condition |
|---|---|---|
| `PRICE_SPIKE` | HIGH | Price moves >5% from rolling average in one tick |
| `CIRCUIT_BREAKER` | CRITICAL | Price moves >10% â€” mimics real exchange halt logic |
| `VOLUME_SPIKE` | MEDIUM | Trade volume >3x rolling average â€” whale detection |

### Circuit Breaker State Machine
```
CLOSED â”€â”€[>10% move]â”€â”€â–º OPEN â”€â”€[5 min timeout]â”€â”€â–º HALF_OPEN â”€â”€[normal]â”€â”€â–º CLOSED
```

---

## Quick Start

### Prerequisites
- Docker Desktop
- 4 GB RAM minimum

### Run

```bash
# Clone the repo
git clone https://github.com/YOUR_USERNAME/stock-it.git
cd stock-it

# Start all 11 services
docker compose up -d --build

# Check all services are healthy
docker compose ps

# Open dashboard
open http://localhost:8088

# Open API docs
open http://localhost:8088/docs

# Inspect Kafka topics
open http://localhost:8090

# Open Grafana  (admin / admin123)
open http://localhost:3001
```

### Teardown

```bash
docker compose down -v
```

---

## API Reference

### REST Endpoints

```bash
# Live prices for all symbols
GET /api/v1/prices

# Current OHLCV window (1m default)
GET /api/v1/ohlcv/AAPL?window_seconds=60

# Recent trades from Redis
GET /api/v1/trades/AAPL?limit=50

# Historical trades from TimescaleDB
GET /api/v1/trades/history?symbol=AAPL&limit=100

# Active alerts
GET /api/v1/alerts?unacked_only=true&severity=HIGH

# Top movers by 5m % change
GET /api/v1/stats/movers

# Simulated order book depth
GET /api/v1/orderbook/AAPL?depth=10

# Buy/sell pressure ratio
GET /api/v1/trades/AAPL/pressure

# Market-wide summary KPIs
GET /api/v1/stats/summary
```

### WebSocket Endpoints

```javascript
// Live price tick (1s intervals, all symbols)
const ws = new WebSocket('ws://localhost:8088/ws/prices');

// Live alert stream
const ws = new WebSocket('ws://localhost:8088/ws/alerts');

// OHLCV window completions
const ws = new WebSocket('ws://localhost:8088/ws/aggregates');
```

### SSE

```bash
curl -N http://localhost:8088/api/v1/stream/prices
```

---

## Data Flow

```
1. Producer generates trade: {symbol, price, quantity, side, exchange, timestamp}
   â””â”€ Uses Geometric Brownian Motion: dS = S(Î¼dt + ÏƒdW)
   â””â”€ 10 symbols: AAPL, GOOGL, MSFT, AMZN, TSLA, BTC-USD, ETH-USD, EUR-USD, GBP-USD, JPY-USD

2. Published to Kafka: raw-trades (partitioned by symbol â†’ in-order per symbol)

3. Stream Processor consumes raw-trades:
   â”œâ”€ Updates Redis: latest price hash, rolling 100-trade deque, sorted-set time-series
   â”œâ”€ Updates OHLCV windows (tumbling 1m/5m/15m) â†’ publishes to trade-aggregates on rollover
   â”œâ”€ Runs anomaly detection â†’ publishes alerts to trade-alerts
   â””â”€ Batch inserts to TimescaleDB every 5s (execute_batch)

4. Alert Engine consumes trade-alerts:
   â”œâ”€ Deduplicates via Redis TTL keys (per alert_type + symbol)
   â”œâ”€ Manages circuit breaker FSM per symbol
   â””â”€ Routes to webhook / log based on severity

5. FastAPI bridges Kafka â†’ WebSocket â†’ Dashboard
   â”œâ”€ Redis reads for real-time data (<1ms)
   â””â”€ TimescaleDB reads for historical queries

6. Prometheus scrapes all 5 services every 5s â†’ Grafana visualizes
```

---

## Key Engineering Decisions

### Lambda Architecture
- **Speed layer (Redis)**: Sub-millisecond reads for latest prices, rolling buffers, current OHLCV window
- **Batch layer (TimescaleDB)**: Full trade history with hypertables, continuous aggregates, and 30-day retention policy

### Partitioning Strategy
`raw-trades` is partitioned by **symbol** â€” guarantees message ordering per symbol, which is required for correct sequential VWAP computation and anomaly detection state.

### Incremental VWAP
```
VWAP = Î£(Price Ã— Volume) / Î£(Volume)
```
Maintained with a `pv_sum` accumulator per window in memory. No recomputation of historical data on each tick â€” O(1) update complexity.

### Alert Deduplication
Redis TTL keys per `(alert_type, symbol)` suppress duplicate alerts:
- `CIRCUIT_BREAKER` â†’ 5-minute cooldown
- `PRICE_SPIKE` â†’ 1-minute cooldown
- `VOLUME_SPIKE` â†’ 30-second cooldown

### Exactly-Once Semantics
- `enable.auto.commit=False` â€” offsets committed only after successful processing
- All DB inserts use `ON CONFLICT DO NOTHING` keyed on `trade_id`

### Backpressure Handling
Kafka producer: `linger.ms=5`, `batch.size=65536`. PostgreSQL writer: 5-second batch flush via `execute_batch` â€” decouples ingestion throughput from storage throughput.

---

## Project Structure

```
stock-it/
â”œâ”€â”€ docker-compose.yml          # Orchestrates all 11 services
â”œâ”€â”€ .env                        # Environment variables
â”œâ”€â”€ start.sh                    # One-command startup script
â”œâ”€â”€ producer/
â”‚   â”œâ”€â”€ trade_producer.py       # GBM trade simulator â†’ Kafka
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ processor/
â”‚   â”œâ”€â”€ stream_processor.py     # VWAP, OHLCV windows, anomaly detection
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ api/
â”‚   â”œâ”€â”€ app.py                  # FastAPI + WebSocket + SSE
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ alerts/
â”‚   â”œâ”€â”€ alert_engine.py         # Dedup, circuit breaker FSM, routing
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ dashboard/
â”‚   â””â”€â”€ index.html              # Real-time trading dashboard
â”œâ”€â”€ monitoring/
â”‚   â”œâ”€â”€ prometheus.yml          # Scrape config for all services
â”‚   â””â”€â”€ grafana/
â”‚       â”œâ”€â”€ provisioning/       # Auto-provision datasources
â”‚       â””â”€â”€ dashboards/         # Pre-built 13-panel dashboard JSON
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ init_db.sql             # TimescaleDB schema, hypertables, retention policy
â””â”€â”€ tests/
    â”œâ”€â”€ test_processor.py       # Unit tests: WindowManager, AnomalyDetector
    â””â”€â”€ test_alert_engine.py    # Unit tests: CircuitBreaker, DeduplicationFilter
```

---

## Tests

```bash
python -m pytest tests/ -v
```

24 unit tests covering VWAP computation, OHLCV window rollover, anomaly detection thresholds, circuit breaker state transitions, and alert deduplication.

---

## Monitoring Metrics

| Metric | Type | Description |
|---|---|---|
| `producer_trades_total` | Counter | Trades published, labeled by symbol/side |
| `producer_latency_seconds` | Histogram | Kafka produce latency p50/p95/p99 |
| `processor_trades_total` | Counter | Trades processed by symbol |
| `processor_alerts_total` | Counter | Alerts fired by type and severity |
| `processor_price` | Gauge | Current price per symbol |
| `alertengine_circuit_breakers_open` | Gauge | Currently open circuit breakers |
| `alertengine_deduped_total` | Counter | Suppressed duplicate alerts |

---

## Q&A

**Q: Why Kafka instead of direct REST/queue?**
> Kafka's durable, partitioned log decouples producers from consumers, allows replay, and enables multiple consumers (processor + API) to independently read the same stream at their own pace.

**Q: How does your pipeline handle backpressure?**
> The stream processor decouples Kafka consumption from PostgreSQL writes using a 5-second batch buffer. Kafka's durable log absorbs upstream bursts while the DB writer flushes at a controlled rate.

**Q: How do you ensure exactly-once processing?**
> Manual offset commits (`enable.auto.commit=False`) â€” offsets advance only after successful processing. Idempotent DB inserts via `ON CONFLICT DO NOTHING` on `trade_id`.

**Q: How does VWAP work in a streaming context?**
> Incremental `pv_sum` accumulator per tumbling window: `VWAP = Î£(priceÃ—volume) / Î£(volume)`. Windows reset on time boundary crossing â€” no historical recomputation needed.

**Q: What's the difference between your speed and batch layers?**
> Redis (speed layer) serves sub-millisecond reads for real-time dashboard data. TimescaleDB (batch layer) handles historical range queries, continuous aggregates, and long-term retention â€” classic Lambda architecture split.
